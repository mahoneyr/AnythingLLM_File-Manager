*Currently available as Version 0.9 (BETA)*

# AnythingLLM File Management Backend ğŸš€

A Django-powered backend service that automates file and workspace management in AnythingLLM through configurable environment settings. The service creates a synchronized mirror of your local filesystem structure within AnythingLLM, automatically handling workspace creation and document embedding. This eliminates the need for manual file management - simply place files in the designated directory and the system handles all workspace organization and embedding processes automatically.

## Features âœ¨

- **Automated File Monitoring** ğŸ“‚: Continuously monitors a specified directory for:
  - âœ… New files
  - ğŸ”„ Modified files
  - ğŸ—‘ï¸ Deleted files
- **AnythingLLM Integration** ğŸ”—:
  - ğŸ“¤ Automatic file upload to AnythingLLM
  - ğŸ“ File reupload when content changes for the local files
  - âŒ Removal of deleted files
  - ğŸ¢ Workspace management (creation and deletion)
  - âš ï¸ Only deleting workspaces created by this backend! No workspaces created via the AnythingLLM UI will be removed.
- **Smart Workspace Management** ğŸ—ï¸:
  - ğŸ“ Automatic workspace creation based on folder structure
  - ğŸ§¹ Cleanup of empty workspaces (when created by this software)
  - ğŸ”„ Embedding updates for modified content
- **Image Processing** ğŸ–¼ï¸:
  - ğŸ“· Optional automatic image description using AI
  - ğŸ” Creates text descriptions of images for better RAG search
  - ğŸ§  Uses Ollama for local AI image processing
- **Configurable Scheduling** â³:
  - ğŸ› ï¸ Customizable monitoring frequency via CRON configuration (set how often it looks for changes based on time)
  - â° Default checking interval: every minute
  - ğŸ“§ Custom updates with a post request to **/update_files/update/**

## Prerequisites ğŸ› ï¸

- ğŸ³ Docker and Docker Compose
- ğŸ§  AnythingLLM instance (works with desktop and docker version)
- ğŸ”‘ Access to AnythingLLM Developer API
- ğŸ‘ï¸ Optional: Ollama for image description functionality

## Configuration âš™ï¸

### Environment Variables ğŸŒ

Configuration is now managed through a `.env` file with the following variables:

```
ANYTHING_LLM_API=your_api_key
ANYTHING_LLM_URL=your_anything_llm_url

USE_CRON=true
CHECK_FILES_CRON=*/1 * * * *

# Image description settings (optional)
OLLAMA_URL=http://localhost:11434/api/generate
IMAGE_DESCRIPTION_ACTIVATE=true
IMAGE_DESCRIPTION_MODEL=gemma3:4b
IMAGE_DESCRIPTION_LANGUAGE=english

SORT_FILES=true
DELETE_UNUSED_FOLDERS=false
```


ğŸ”‘ You can find the developer API Key here: **AnythingLLM Settings -> Tools -> Developer API -> Generate New API Key**

ğŸŒ You can get the URL from the Developer API Window -> Click on **"Read the API documentation"** -> Example URL: `http://192.168.80.35:3001/api/docs/` -> Use `http://192.168.80.35:3001` without a trailing `/`

### Volume Configuration ğŸ“

Specify the directory to monitor in `docker-compose.yml`:

```yaml
volumes:
  - C:\YOUR_PATH:/app/AnythingLLM
```

âš ï¸ **Important**: You must modify the volume path in `docker-compose.yml` from the default `C:\AnythingTest:/app/AnythingLLM` to your own local directory that should be monitored.

ğŸ“‚ The program will scan every folder within the specified path.

Example:
- `C:\MyAnythingLLM_folder\Homework`
- `C:\MyAnythingLLM_folder\Contracts`
- `C:\MyAnythingLLM_folder\ActualHomework`

Will create the Workspaces:
- **Homework**
- **Contracts**
- **ActualHomework**

ğŸ—‘ï¸ These workspaces also get deleted when the local folders are removed.

## Image Description Feature ğŸ–¼ï¸

This feature automatically creates text descriptions for image files when enabled:

1. **How it works:**
   - Detects image files in monitored folders (.jpg, .jpeg, .png, .gif, .bmp, .tiff, .webp)
   - Sends images to Ollama for AI-based description
   - Creates a `.image_description` file alongside each image
   - Only the text description gets uploaded to AnythingLLM, making embeddings more efficient

2. **Configuration:**
   - Enable with `IMAGE_DESCRIPTION_ACTIVATE=true`
   - Configure Ollama URL with `OLLAMA_URL=http://your-ollama-instance:11434/api/generate`
   - Select model with `IMAGE_DESCRIPTION_MODEL=gemma3:4b` (or another compatible model)
   - Choose language with `IMAGE_DESCRIPTION_LANGUAGE=english` (or other language)

## File Sorting Feature ğŸ—‚ï¸ ğŸ“ ğŸ”„

âš ï¸ **BETA Feature**: The file sorting functionality is currently in beta and not completely tested yet. Use with caution. ğŸ§ª ğŸ”

This feature automatically organizes documents into folders based on their workspace associations. This feature is only required if you are uploading and embeding through the AnythingLLM Frontend, since automatic uploads from this App already manages files. ğŸŒŸ âœ¨

1. **How it works:** ğŸ› ï¸
   - ğŸ” Analyzes which workspaces each document is embedded in
   - ğŸ“ Creates folders with workspace names if they don't already exist
   - ğŸ”„ Moves documents into folders that match their workspace names
   - 1ï¸âƒ£ For documents in exactly one workspace: moves them to a folder named after that workspace
   - ğŸ”€ For documents in multiple workspaces: special handling applied (feature in development)
   - ğŸ“Œ Documents not in any workspace remain in their original location

2. **Configuration:** âš™ï¸
   - âœ… Enable with `SORT_FILES=true` in your `.env` file
   - ğŸ§¹ Optionally enable `DELETE_UNUSED_FOLDERS=true` to clean up empty folders
   
3. **Use cases:** ğŸ’¼
   - ğŸ—„ï¸ Automatically organize documents by their logical workspace groupings
   - ğŸ§© Maintain cleaner file structure that mirrors your AnythingLLM workspaces
   - ğŸ“š Simplify document management for large knowledge bases

4. **Limitations (Beta):** âš ï¸
   - ğŸ”€ Documents in multiple workspaces may not be sorted optimally yet
   - ğŸ¢ Large document collections may take longer to process
   - ğŸ§© Some edge cases may not be handled properly

## Installation and Setup ğŸš€

1. **Clone the repository**:
```bash
git clone https://github.com/MrMarans/AnythingLLM_File-Manager.git
```

2. **Configure your environment**:
   - ğŸ› ï¸ Create a `.env` file with required environment variables (check out the `.env.example` file)
   - ğŸ”‘ Set your API key, AnythingLLM URL, watched folder path
   - ğŸ“‚ Configure docker-compose.yml with the correct volume mapping for your monitored directory

3. **Start the service**:
```bash
docker-compose up -d
```

ğŸ†™ **Updating to a new version or updating the configuration?** Use:
```bash
docker-compose down
docker-compose up -d --build
```

## How It Works ğŸ› ï¸

1. **File Monitoring** ğŸ”:
   - Periodically checks the monitored directory based on the configured CRON schedule â³
   - Detects **new, modified, and deleted** files âœ…
   - Maintains a database of detected files ğŸ—ƒï¸

2. **AnythingLLM Integration** ğŸ”—:
   - ğŸ“¤ New files are automatically uploaded
   - ğŸ“ Modified files trigger updates
   - âŒ Deleted files are removed
   - ğŸ¢ Workspaces are created based on folder structure

3. **Image Processing** (when enabled) ğŸ–¼ï¸:
   - ğŸ” Detects image files in monitored directories
   - ğŸ§  Sends them to Ollama for description generation
   - ğŸ“ Saves descriptions as separate files
   - ğŸ“¤ Uploads only the text descriptions to AnythingLLM

4. **Workspace Management** ğŸ—ï¸:
   - ğŸ“ Creates workspaces automatically for new folders
   - ğŸ”„ Updates embeddings when files change
   - ğŸ§¹ Removes empty workspaces to maintain cleanliness

## CRON Schedule Examples â°

You can modify the `CHECK_FILES_CRON` environment variable to adjust the checking frequency:

- `*/1 * * * *` - ğŸ”„ Every minute (default)
- `*/5 * * * *` - â³ Every 5 minutes
- `0 * * * *` - ğŸ•’ Every hour
- `0 */2 * * *` - â²ï¸ Every 2 hours
- `0 9-17 * * 1-5` - â° Every hour between 9 AM and 5 PM, Monday to Friday

To deactivate CRON Scheduler, set `USE_CRON=false` in the `.env` file


## Update via API

You can let the files manually update with a post request to the **ip:port/update_files/update/** endpoint.
For most people it will be **http://localhost:8000/update_files/update/**

## Web UI Interface ğŸ–¥ï¸ ğŸ–±ï¸

The application includes a simple web UI for managing your AnythingLLM files directly from your browser ğŸŒ:

1. **How to access:** ğŸ”—
   - Open your browser and navigate to the application's base URL (e.g., **http://localhost:8000/**)
   - You'll see a user-friendly dashboard with action buttons

2. **Available actions:** ğŸ®
   - ğŸ“¤ **Full Upload and Cleaning** - Upload files and perform cleaning operations
   - ğŸ—‚ï¸ **Sort Files** - Sort files into appropriate folders based on workspace associations
   - ğŸ§¹ **Clean Folders** - Delete unused folders
   - ğŸ” **Scan Files** - Check for new, changed, or deleted files (doesn't upload anything)
   - ğŸ–¼ï¸ **Create Image Descriptions** - Generate descriptions for all images

3. **Usage:** ğŸ‘†
   - Simply click on the desired action button
   - The system will execute the requested operation
   - Results will be displayed in the response area below the buttons

This interface provides a convenient alternative to API calls or waiting for scheduled CRON jobs to run. ğŸ’«

## Troubleshooting ğŸ› ï¸

Common issues and their solutions:

1. **Files not being detected** ğŸ§:
   - ğŸ” Check the volume mounting in `docker-compose.yml`
   - ğŸ”‘ Verify file permissions
   - ğŸ“ Check the logs for any errors

2. **AnythingLLM connection issues** ğŸ”Œ:
   - âœ… Verify `ANYTHING_LLM_URL` is correct
   - ğŸ”‘ Ensure `ANYTHING_LLM_API` key is valid
   - ğŸŒ Check network connectivity

3. **Schedule not running** â³:
   - âœ… Verify `CHECK_FILES_CRON` format
   - ğŸ“œ Check container logs for scheduling errors
   - ğŸŒ Ensure the container has the correct timezone settings

4. **Image description not working** ğŸ–¼ï¸:
   - âœ… Check Ollama is running and accessible
   - ğŸ” Verify `OLLAMA_URL` is correct
   - ğŸ“ Ensure the specified model is available in your Ollama instance

## Logs ğŸ“œ

The service logs all operations and errors. Access the logs using:

```bash
docker-compose logs -f
```

## Support ğŸ¤

For issues, questions, or contributions:
- ğŸ“ Create an issue in the repository
- Make `VERBOSE` true in the .env file, this will print more logs
- ğŸ› ï¸ Include logs and configuration details when reporting issues


## Upcoming Changes ğŸš€

- ğŸ› ï¸ Additional API endpoints for granular control
- ğŸ–¼ï¸ Endpoint for on-demand image description
- ğŸ“ API documentation improvements
- ğŸ‘¤ Face Recognition Feature for Image Description
- ğŸ¯ Check if filetype is supported by AnythingLLM
- ğŸš€ Much More exciting features!

- Version 1.0 will release with AnythingLLM Desktop Support and granular API endpoints. No releasdate or window yet clear!

## Security Information ğŸ”’

âš ï¸ **No security testing has been conducted. Use at your own risk.** This has not been tested for production. Please review the `settings.py` file and adjust as needed. You have been warned.

ğŸ” If you have security expertise, **pull requests with security improvements are welcome!**

## License ğŸ“œ

MIT
